{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average words per sentence of different subreddits\n",
    "\n",
    "### Background\n",
    "An analysis of the average word count per sentence of comments from the most popular Subreddits. \n",
    "\n",
    "wps = words per sentence\n",
    "\n",
    "### Subreddits analyzed (top 20 most subscribed as of April 2019):\n",
    "\n",
    "### Contents\n",
    "1. [Setup](#1.-Setup)\n",
    "2. [Average Words Per Sentence for Comments](#2-Average-Words-Per-Sentence-for-Comments)\n",
    "3. [Average wps for Submission](#3.-Average-wps-for-submission)\n",
    "4. [Average wps for Subreddit](#4.-Average-wps-for-subreddit)\n",
    "5. [Data Visualization](#5.-Data-Visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import string\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-17 21:45:41.067576]credfile.json .......... is being used as credfile\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Load credfile and display when last updated\n",
    "credfile = 'credfile.json'\n",
    "credfile_prefix = ''\n",
    "\n",
    "# Read credentials to a dictionary\n",
    "with open(credfile) as fh:\n",
    "    creds = json.loads(fh.read())\n",
    "\n",
    "print(f\"[{datetime.datetime.now()}]\" + f\"{credfile} {'.' * 10} is being used as credfile\")\n",
    "\n",
    "reddit = praw.Reddit(client_id=creds['client_id'],\n",
    "                     client_secret=creds['client_secret'],\n",
    "                     user_agent=creds['user_agent']\n",
    "                    )\n",
    "\n",
    "print(reddit.read_only)  # Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['soccer', \n",
    "                  'nfl', \n",
    "                  'cfb',\n",
    "                  'nba', \n",
    "                  'hockey',\n",
    "                  'baseball',\n",
    "                  'mma', \n",
    "                  'tennis', \n",
    "                  'golf',\n",
    "                  'cricket', \n",
    "                  'rugbyunion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Average Words Per Sentence for Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_words(word_list):\n",
    "    \"\"\"\n",
    "    Remove stopwords, one-caracter words, and convert words to lowercase.\n",
    "    Given a list of tokenized words)\n",
    "    \"\"\"\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in word_list]\n",
    "    \n",
    "    # convert to lower case\n",
    "    stripped_lower = [word.lower() for word in stripped]\n",
    "\n",
    "    # Remove one character words\n",
    "    text_tokenized = [word for word in stripped_lower if len(word) > 2]\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_stopped = [w for w in text_tokenized if not w in stop_words]\n",
    "    \n",
    "    return text_stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentence_len_comment(comment):\n",
    "    \n",
    "    sentences = sent_tokenize(comment)\n",
    "    words = word_tokenize(comment)   \n",
    "\n",
    "    cleaned_list = [ x for x in words if len(x) > 2 ]\n",
    "    \n",
    "    try:\n",
    "        avg_sent_len = round(len(cleaned_list) / len(sentences), 2)\n",
    "    except ZeroDivisionError:\n",
    "        avg_sent_len = 0\n",
    "        \n",
    "    return avg_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission comments average wps:  11.942354694485836\n",
      "Submission upvote ratio:  0.88\n"
     ]
    }
   ],
   "source": [
    "submission = reddit.submission(id='ba4dyn')\n",
    "\n",
    "# iterate over top comments in the submission and\\= create list of sentences\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "total_submission_len = 0\n",
    "for top_level_comment in submission.comments[1:]: # Skip AutoMod comment\n",
    "    avg_sent_len = avg_sentence_len_comment(top_level_comment.body.replace('“', '').replace('”', ''))         \n",
    "    total_submission_len += avg_sent_len\n",
    "\n",
    "avg_submission_len = total_submission_len / len(submission.comments[1:])\n",
    "\n",
    "print(\"Submission comments average wps: \", avg_submission_len)\n",
    "print(\"Submission upvote ratio: \", submission.upvote_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Average wps for Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on one submission using `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_wps_submission(comment_list):\n",
    "    \"\"\"\n",
    "    Iterate over list of comments in a submission and calculate the average words\n",
    "    per sentence of all top-level comments\n",
    "    \"\"\"\n",
    "    total_submission_sentence_len = 0\n",
    "    for comment in comment_list:\n",
    "        avg_sent_len = avg_sentence_len_comment(comment.body.replace('“', '').replace('”', ''))                 \n",
    "        total_submission_sentence_len += avg_sent_len\n",
    "\n",
    "    try:\n",
    "        avg_wps_submission = total_submission_sentence_len / len(comment_list)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Submission has 0 comments, continuing...\")\n",
    "        avg_wps_submission = 0\n",
    "        \n",
    "    return avg_wps_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Average wps for Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_wps_subreddit(submission_list):\n",
    "    \"\"\"\n",
    "    Iterate over all x number of submissions and get the average words \n",
    "    per sentence for the entire subreddit\n",
    "    \"\"\"\n",
    "    total_wps_subreddit = 0\n",
    "    for submission in submission_list:\n",
    "        # iterate over top comments in the submission and create list of sentences\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        avg_wps_per_submission = avg_wps_submission(list(submission.comments))\n",
    "\n",
    "        # keep running total of totals for entire subreddit\n",
    "        total_wps_subreddit += avg_wps_per_submission\n",
    "    \n",
    "    avg_wps_subreddit = total_wps_subreddit / len(submission_list)\n",
    "    \n",
    "    return avg_wps_subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_to_regular(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: default_to_regular(v) for k, v in d.items()}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_data(submission_list):\n",
    "    nested_dict = lambda: defaultdict(nested_dict)\n",
    "    submission_data = nested_dict()\n",
    "    for submission in submission_list:\n",
    "        # iterate over top comments in the submission and create list of sentences\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        submission_id = submission.id\n",
    "        submission_data[submission_id]['upvotes'] = submission.ups\n",
    "        submission_data[submission_id]['upvotes_ratio'] = submission.upvote_ratio\n",
    "        submission_data[submission_id]['date'] = datetime.datetime.fromtimestamp(int(submission.created_utc)).strftime(\"%m/%d/%y %H:%M:%S\")\n",
    "        submission_data[submission_id]['comments'] = len(list(submission.comments))\n",
    "        submission_data[submission_id]['avg_comment_wps'] = round(avg_wps_submission(list(submission.comments)), 2)\n",
    "\n",
    "    submission_data_dict = default_to_regular(submission_data)\n",
    "    return submission_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate over the list of Subreddits\n",
    "`lt` is the number of submissions returned per subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_subs(subreddit_list, method, limit):\n",
    "    \"\"\"\n",
    "    Iterates over a list of subreddit names\n",
    "    \"\"\"\n",
    "    lt = limit\n",
    "    nested_dict = lambda: defaultdict(nested_dict)\n",
    "    submission_data = nested_dict()\n",
    "    start = time.time()\n",
    "    for sub in subreddit_list:\n",
    "        subreddit = reddit.subreddit(sub)\n",
    "        if method == \"hot\":\n",
    "            submission_list = list(subreddit.hot('day', limit=limit))\n",
    "        elif method == \"controversial\":\n",
    "            submission_list = list(subreddit.controversial('day', limit=limit))\n",
    "        elif method == \"top\":\n",
    "            submission_list = list(subreddit.top('day', limit=limit))\n",
    "        elif method == \"new\":\n",
    "            submission_list = list(subreddit.new(limit=limit))\n",
    "        else:\n",
    "            raise ValueError\n",
    "            print(\"Please select a valid type from: hot, controversial, top, new\")\n",
    "        submission_data[sub] = get_submission_data(submission_list)\n",
    "    \n",
    "    # Convert defaultdict to regular\n",
    "    submission_data_dict = default_to_regular(submission_data)\n",
    "\n",
    "    end = time.time()\n",
    "    net = net = end-start\n",
    "    print(f\"Runtime: {round(net, 2)}s\")\n",
    "    \n",
    "    return submission_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 711.66s\n"
     ]
    }
   ],
   "source": [
    "submission_data = iterate_over_subs(subreddit_list, \"top\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be6l7h': {'upvotes': 13617,\n",
       "  'upvotes_ratio': 0.96,\n",
       "  'date': '04/17/19 07:21:10',\n",
       "  'comments': 81,\n",
       "  'avg_comment_wps': 6.37},\n",
       " 'becx3a': {'upvotes': 12695,\n",
       "  'upvotes_ratio': 0.92,\n",
       "  'date': '04/17/19 16:54:51',\n",
       "  'comments': 1762,\n",
       "  'avg_comment_wps': 7.11},\n",
       " 'be7ccu': {'upvotes': 11800,\n",
       "  'upvotes_ratio': 0.96,\n",
       "  'date': '04/17/19 08:43:36',\n",
       "  'comments': 225,\n",
       "  'avg_comment_wps': 8.77},\n",
       " 'be607a': {'upvotes': 8688,\n",
       "  'upvotes_ratio': 0.95,\n",
       "  'date': '04/17/19 06:05:43',\n",
       "  'comments': 51,\n",
       "  'avg_comment_wps': 7.42},\n",
       " 'becwtj': {'upvotes': 7042,\n",
       "  'upvotes_ratio': 0.95,\n",
       "  'date': '04/17/19 16:54:09',\n",
       "  'comments': 438,\n",
       "  'avg_comment_wps': 5.58},\n",
       " 'bebqyw': {'upvotes': 5962,\n",
       "  'upvotes_ratio': 0.94,\n",
       "  'date': '04/17/19 15:10:47',\n",
       "  'comments': 439,\n",
       "  'avg_comment_wps': 3.56},\n",
       " 'be59h7': {'upvotes': 4861,\n",
       "  'upvotes_ratio': 0.98,\n",
       "  'date': '04/17/19 04:14:10',\n",
       "  'comments': 24,\n",
       "  'avg_comment_wps': 10.14},\n",
       " 'beco60': {'upvotes': 4222,\n",
       "  'upvotes_ratio': 0.97,\n",
       "  'date': '04/17/19 16:32:25',\n",
       "  'comments': 457,\n",
       "  'avg_comment_wps': 4.6},\n",
       " 'bebtdz': {'upvotes': 4181,\n",
       "  'upvotes_ratio': 0.98,\n",
       "  'date': '04/17/19 15:16:40',\n",
       "  'comments': 94,\n",
       "  'avg_comment_wps': 4.2},\n",
       " 'be74nh': {'upvotes': 3122,\n",
       "  'upvotes_ratio': 0.99,\n",
       "  'date': '04/17/19 08:21:46',\n",
       "  'comments': 68,\n",
       "  'avg_comment_wps': 6.29}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data['soccer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(submission_dict):\n",
    "    submission_df = pd.DataFrame()\n",
    "    \n",
    "    for key, value in submission_data.items():\n",
    "        for submission_id, data in value.items():\n",
    "            submission_df.loc[submission_id, 'upvotes'] = data['upvotes']\n",
    "            submission_df.loc[submission_id, 'upvotes_ratio'] = data['upvotes_ratio'] \n",
    "            submission_df.loc[submission_id, 'date'] = data['date'] \n",
    "            submission_df.loc[submission_id, 'comments'] = data['comments'] \n",
    "            submission_df.loc[submission_id, 'avg_comment_wps'] = data['avg_comment_wps'] \n",
    "            submission_df.loc[submission_id, 'subreddit'] = key \n",
    "            \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = convert_to_df(submission_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upvotes</th>\n",
       "      <th>upvotes_ratio</th>\n",
       "      <th>date</th>\n",
       "      <th>comments</th>\n",
       "      <th>avg_comment_wps</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>be6l7h</th>\n",
       "      <td>13617.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>04/17/19 07:21:10</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>becx3a</th>\n",
       "      <td>12695.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>04/17/19 16:54:51</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be7ccu</th>\n",
       "      <td>11800.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>04/17/19 08:43:36</td>\n",
       "      <td>225.0</td>\n",
       "      <td>8.77</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be607a</th>\n",
       "      <td>8688.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>04/17/19 06:05:43</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.42</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>becwtj</th>\n",
       "      <td>7042.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>04/17/19 16:54:09</td>\n",
       "      <td>438.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        upvotes  upvotes_ratio               date  comments  avg_comment_wps  \\\n",
       "be6l7h  13617.0           0.96  04/17/19 07:21:10      81.0             6.37   \n",
       "becx3a  12695.0           0.92  04/17/19 16:54:51    1762.0             7.11   \n",
       "be7ccu  11800.0           0.96  04/17/19 08:43:36     225.0             8.77   \n",
       "be607a   8688.0           0.95  04/17/19 06:05:43      51.0             7.42   \n",
       "becwtj   7042.0           0.95  04/17/19 16:54:09     438.0             5.58   \n",
       "\n",
       "       subreddit  \n",
       "be6l7h    soccer  \n",
       "becx3a    soccer  \n",
       "be7ccu    soccer  \n",
       "be607a    soccer  \n",
       "becwtj    soccer  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By subreddit\n",
    "Take average of all fields for each subreddit. Then, lets examine the average words per sentance for our list of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>avg_comment_wps</th>\n",
       "      <th>comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>upvotes_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tennis</td>\n",
       "      <td>6.266</td>\n",
       "      <td>9.8</td>\n",
       "      <td>150.3</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>soccer</td>\n",
       "      <td>6.404</td>\n",
       "      <td>363.9</td>\n",
       "      <td>7619.0</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>golf</td>\n",
       "      <td>6.608</td>\n",
       "      <td>22.7</td>\n",
       "      <td>370.3</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nba</td>\n",
       "      <td>7.100</td>\n",
       "      <td>125.4</td>\n",
       "      <td>5768.8</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseball</td>\n",
       "      <td>7.145</td>\n",
       "      <td>54.3</td>\n",
       "      <td>1486.6</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rugbyunion</td>\n",
       "      <td>7.553</td>\n",
       "      <td>10.3</td>\n",
       "      <td>246.2</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hockey</td>\n",
       "      <td>7.581</td>\n",
       "      <td>432.9</td>\n",
       "      <td>7802.1</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cfb</td>\n",
       "      <td>7.908</td>\n",
       "      <td>41.1</td>\n",
       "      <td>329.8</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cricket</td>\n",
       "      <td>8.070</td>\n",
       "      <td>223.8</td>\n",
       "      <td>331.4</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mma</td>\n",
       "      <td>8.627</td>\n",
       "      <td>54.4</td>\n",
       "      <td>1295.7</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nfl</td>\n",
       "      <td>8.853</td>\n",
       "      <td>107.6</td>\n",
       "      <td>1852.6</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  avg_comment_wps  comments  upvotes  upvotes_ratio\n",
       "10      tennis            6.266       9.8    150.3          0.955\n",
       "9       soccer            6.404     363.9   7619.0          0.960\n",
       "3         golf            6.608      22.7    370.3          0.963\n",
       "6          nba            7.100     125.4   5768.8          0.957\n",
       "0     baseball            7.145      54.3   1486.6          0.971\n",
       "8   rugbyunion            7.553      10.3    246.2          0.893\n",
       "4       hockey            7.581     432.9   7802.1          0.968\n",
       "1          cfb            7.908      41.1    329.8          0.905\n",
       "2      cricket            8.070     223.8    331.4          0.965\n",
       "5          mma            8.627      54.4   1295.7          0.958\n",
       "7          nfl            8.853     107.6   1852.6          0.963"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df_pivot = pd.pivot_table(submission_df, index='subreddit', aggfunc='mean')\n",
    "submission_df_pivot.reset_index(inplace=True)\n",
    "submission_df_pivot.sort_values(by='avg_comment_wps', inplace=True)\n",
    "submission_df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "pal = sns.color_palette(\"Greens_d\", len(submission_df_pivot))\n",
    "ax = sns.barplot(x=\"subreddit\", \n",
    "                 y=\"avg_comment_wps\", \n",
    "                 data=submission_df_pivot,\n",
    "                 palette=np.array(pal[::-1]))\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.title(\"Avg Words per Sentence in Comments per Subreddit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_file\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "output_file(\"subreddit_wps.html\")\n",
    "\n",
    "subreddit = list(submission_df_pivot['subreddit'])\n",
    "words_per_sentence = list(submission_df_pivot['avg_comment_wps'])\n",
    "\n",
    "p = figure(x_range=subreddit, plot_height=250, title=\"Fruit words_per_sentence\",\n",
    "           toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.vbar(x=subreddit, top=words_per_sentence, width=0.9)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
