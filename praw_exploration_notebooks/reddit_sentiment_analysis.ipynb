{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Comments for Reddit Posts\n",
    "Using nltk, I will attempt to quantify the sentiment of all comments on a post. This can then be expanded to multiple posts or entire subreddits. This analysis can be useful for certain subreddits to see how emotion changes over time. \n",
    "\n",
    "For example, being able to gauge the sentiment for various political subreddits over time, or in the lead up to an election can help determine if one candidate has the edge over another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-22 14:39:50.445092]credfile.json .......... is being used as credfile\n"
     ]
    }
   ],
   "source": [
    "# Load credfile and display when last updated\n",
    "credfile = 'credfile.json'\n",
    "credfile_prefix = ''\n",
    "\n",
    "# Read credentials to a dictionary\n",
    "with open(credfile) as fh:\n",
    "    creds = json.loads(fh.read())\n",
    "\n",
    "print(f\"[{datetime.datetime.now()}]\" + f\"{credfile} {'.' * 10} is being used as credfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=creds['client_id'],\n",
    "                     client_secret=creds['client_secret'],\n",
    "                     user_agent=creds['user_agent']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only)  # Output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with one post and analyze all comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = reddit.submission(id='ba7uqx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save comments as a list\n",
    "top_level_comments = list(submission.comments)\n",
    "all_comments = submission.comments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top level comments:  131\n",
      "Total number of comments:      602\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of top level comments: \", len(top_level_comments))\n",
    "print(\"Total number of comments:     \", len(all_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votes:   1\n",
      "Author:  AutoModerator\n",
      "Body:    **Mirrors / Alternate angles**\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/soccer) if you have any questions or concerns.*\n",
      "===================\n",
      "Votes:   1501\n",
      "Author:  FlyingArab\n",
      "Body:    This was the most Diego Costa sequence ever\n",
      "===================\n",
      "Votes:   2238\n",
      "Author:  Sinnedd\n",
      "Body:    Damn, Costa must have insulted this guy’s entire family \n",
      "===================\n",
      "Votes:   774\n",
      "Author:  yammington\n",
      "Body:    Simeone is gonna shank Costa at half time.\n",
      "===================\n",
      "Votes:   1359\n",
      "Author:  Juggernautspammer\n",
      "Body:    What the fuck could he have said to get a straight red holy shit \n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "for comment in top_level_comments[:5]: # view the top 5 comments\n",
    "    print(\"Votes:  \", comment.score)\n",
    "    print(\"Author: \", comment.author)\n",
    "    print(\"Body:   \",  comment.body)\n",
    "    print(\"===================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over top comments in the submission and\\= create list of sentences\n",
    "submission.comments.replace_more(limit=None)\n",
    "top_level_comment_list = []\n",
    "top_level_comment_string = ''\n",
    "for top_level_comment in submission.comments[1:]: # Skip AutoMod comment\n",
    "    top_level_comment_list.append(top_level_comment.body)\n",
    "    top_level_comment_string += (str(top_level_comment.body)+'. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This was the most Diego Costa sequence ever',\n",
       " 'Damn, Costa must have insulted this guy’s entire family ',\n",
       " 'Simeone is gonna shank Costa at half time.',\n",
       " 'What the fuck could he have said to get a straight red holy shit ',\n",
       " 'I am so confused']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_level_comment_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This was the most Diego Costa sequence ever. Damn, Costa must have insulted this guy’s entire family . Simeone is gonna shank Costa at half time.. What the fuck could he have said to get a straight red holy shit . I am so confused. Thats our boy. Damn, the way atletico players surrounded the ref was inviting another red. The way the referee gets crowded in la Liga disgusts me every time. . classic Diego Costa. Gently whispered \"Ur mom gay lol\" to the ref.\\n\\nFair red imo.. [deleted]. Imagine being'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_level_comment_string[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polarity & Subjectivity using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity score:      -0.006176127142461299\n",
      "Subjectivity score:  0.4890894786842422\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "analysis = TextBlob(top_level_comment_string)\n",
    "print('Polarity score:     ', analysis.sentiment[0])\n",
    "print('Subjectivity score: ', analysis.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Readability'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-349c6c035aa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mreadability\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReadability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_level_comment_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflesch_kincaid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Readability'"
     ]
    }
   ],
   "source": [
    "from readability import Readability\n",
    "\n",
    "r = Readability(top_level_comment_string)\n",
    "fk = r.flesch_kincaid()\n",
    "\n",
    "print(\"Flesch-kincaid score:       \", fk.score)\n",
    "print(\"Flesch-kincaid grade level: \", fk.grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, lets expand this to the hot submissions for the top 100 subreddits\n",
    "\n",
    "We will identify the top subreddits by number of subscribers. Then, for each subreddit I will calculate various metrics including comment sentiment, subjectivity and engagement metrics (upvote ratio, number of comments) for the top 10 hottest posts at the moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "n_posts = 10\n",
    "\n",
    "# Get list of subs\n",
    "top_subs = pd.read_html('https://redditmetrics.com/top')[0]\n",
    "top_subs = top_subs[top_subs['Reddit']!='announcements'] # announcements subreddit doesn't count\n",
    "top_subs = top_subs[top_subs['Rank']<=100]\n",
    "list_of_subs = [x.split('/')[-1] for x in top_subs['Reddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now() # Start timer\n",
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for sub in list_of_subs:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    sub_n_subscribers = subreddit.subscribers\n",
    "    sub_name = subreddit.display_name\n",
    "\n",
    "    for submission in subreddit.hot(limit=n_posts):\n",
    "        # Get all top-level comments\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        all_comments = submission.comments.list()\n",
    "\n",
    "        # Calculate sentiment and subjectivity\n",
    "        submission_sentiment_total = 0\n",
    "        submission_subjectivity_total = 0\n",
    "        for comment in all_comments:\n",
    "            analysis = TextBlob(comment.body)\n",
    "            submission_sentiment_total = submission_sentiment_total + analysis.sentiment[0]\n",
    "            submission_subjectivity_total = submission_subjectivity_total + analysis.subjectivity\n",
    "\n",
    "        sentiment_avg = submission_sentiment_total / len(all_comments)\n",
    "        subjectivity_avg = submission_subjectivity_total / len(all_comments)\n",
    "\n",
    "        # Append to DF\n",
    "        metrics_df = metrics_df.append({'subreddit': sub_name,\n",
    "                                        'submission_id': submission.id,\n",
    "                                        'submission_score': submission.score,\n",
    "                                        'submission_upvote_ratio': submission.upvote_ratio,\n",
    "                                        'n_comments': len(all_comments),\n",
    "                                        'sentiment': sentiment_avg,\n",
    "                                        'subjectivity': subjectivity_avg}, ignore_index=True\n",
    "                                      )\n",
    "        \n",
    "    print(f\"Finished running r/{sub}\")\n",
    "    \n",
    "end_time = datetime.datetime.now() # Finish timer\n",
    "\n",
    "print(f\"Runtime: {((end_time - start_time).seconds) / 60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Ideas\n",
    "* Live analysis of comments, scores etc.\n",
    "* E.g. live sentiment analysis of comments of the most popular subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
